{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ktaBjjiRYC0",
        "outputId": "fce69fac-381f-4a70-db5d-081d220a4002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\n",
            "Fetched 186 kB in 0s (735 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126210 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install pdf2image\n",
        "!apt-get install -y poppler-utils\n",
        "from pdf2image import convert_from_path\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_pdf_to_images(pdf_path, output_folder):\n",
        "  if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "    # Convert PDF to images\n",
        "    images = convert_from_path(pdf_path)\n",
        "    image_paths=[]\n",
        "    # save images nad paths\n",
        "    for i,image in enumerate(images):\n",
        "      image_path=os.path.join(output_folder,f\"page_{i+1}.jpg\")\n",
        "      image.save(image_path,\"JPEG\")\n",
        "      image_paths.append(image_path)\n",
        "    return image_paths"
      ],
      "metadata": {
        "id": "jLuzPH57RcrB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path=\"/content/Things mother used to make.pdf\"\n",
        "output_folder=\"images/\"\n",
        "image_paths=convert_pdf_to_images(pdf_path,output_folder)\n"
      ],
      "metadata": {
        "id": "7xMRArqUReaJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai  # Main Gemini API library\n",
        "import os"
      ],
      "metadata": {
        "id": "uQuSWVtJR1ka"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('Gemini_API')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n"
      ],
      "metadata": {
        "id": "7N2JqE8BR2X_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "model = \"gemini-1.5-flash\"\n"
      ],
      "metadata": {
        "id": "NOXoDIKKSCBR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown,display"
      ],
      "metadata": {
        "id": "RiYEJf4MSL9Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/images/page_12.jpg\n",
        "image_path=\"/content/images/page_23.jpg\"\n",
        "with open(image_path,\"rb\") as image_file:\n",
        "  image_data=encoded_string=base64.b64encode(image_file.read()).decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "H5Az63qvSWOZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define improved system prompt\n",
        "system_prompt2 = \"\"\"\n",
        "Please analyze the content of this image and extract any related recipe information into structure components.\n",
        "Specifically, extra the recipe title, list of ingredients, step by step instructions, cuisine type, dish type, any relevant tags or metadata.\n",
        "The output must be formatted in a way suited for embedding in a Retrieval Augmented Generation (RAG) system.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "A6P1rigDSTGQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gpt_response2():\n",
        "  response = model.generate_content(\n",
        "    [\n",
        "        system_prompt2,\n",
        "        \"This is the image from the recipe page.\",\n",
        "        {\"mime_type\": \"image/jpeg\", \"data\": image_data}\n",
        "    ]\n",
        ")\n",
        "  p=response.text\n",
        "  return display(Markdown(p))"
      ],
      "metadata": {
        "id": "rvbJgVLES2Sd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_gpt_response2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "dqEB0gTiS5Xf",
        "outputId": "58979ace-49bb-4b6e-9fc3-8aece6a7ea8f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n{\n  \"recipe_title\": \"Bannocks\",\n  \"cuisine_type\": \"Unknown\",\n  \"dish_type\": \"Bread\",\n  \"ingredients\": [\n    \"1 Cupful of Thick Sour Milk\",\n    \"1½ Cupful of Sugar\",\n    \"1 Egg\",\n    \"2 Cupfuls of Flour\",\n    \"1½ Cupful of Indian Meal\",\n    \"1 Teaspoonful of Soda\",\n    \"A pinch of Salt\"\n  ],\n  \"instructions\": [\n    \"Make the mixture stiff enough to drop from a spoon.\",\n    \"Drop mixture, size of a walnut, into boiling fat.\",\n    \"Serve warm, with maple syrup.\"\n  ],\n  \"tags\": [\"bread\", \"bannock\"]\n}\n```\n\n```json\n{\n  \"recipe_title\": \"Boston Brown Bread\",\n  \"cuisine_type\": \"Unknown\",\n  \"dish_type\": \"Bread\",\n  \"ingredients\": [\n    \"1 Cupful of Rye Meal\",\n    \"1 Cupful of Graham Meal\",\n    \"1½ Cupful of Flour\",\n    \"1 Cupful of Indian Meal\",\n    \"1 Cupful of Sweet Milk\",\n    \"1 Cupful of Sour Milk\",\n    \"1 Cupful of Molasses\",\n    \"½ Teaspoonful of Salt\",\n    \"1 Heaping Teaspoonful of Soda\"\n  ],\n  \"instructions\": [\n    \"Stir the meals and salt together.\",\n    \"Beat the soda into the molasses until it foams; add sour milk, mix all together\",\n    \"Pour into a tin pail which has been well greased, if you have no brown-bread steamer.\"\n  ],\n  \"tags\": [\"bread\", \"boston brown bread\"]\n}\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "fFSF0JRaS8Ga"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_recipes = []\n",
        "skipped_recipes = []  # Track skipped recipes\n",
        "\n",
        "for image_path in image_paths:\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    image_data = encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "  try:\n",
        "    response = model.generate_content(\n",
        "      [\n",
        "          system_prompt2,\n",
        "          \"This is the image from the recipe page.\",\n",
        "          {\"mime_type\": \"image/jpeg\", \"data\": image_data}\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "      gpt_response = response.text\n",
        "      extracted_recipes.append({\"image_path\": image_path, \"recipe info\": gpt_response})\n",
        "      print(f\"extracted info {image_path}:\\n {gpt_response}\\n \")\n",
        "    except ValueError as ve:\n",
        "      # Check if it's a copyright error\n",
        "      if \"copyrighted material\" in str(ve):\n",
        "        print(f\"Skipping {image_path}: Content appears to be copyrighted\")\n",
        "        skipped_recipes.append(image_path)\n",
        "      else:\n",
        "        # Re-raise other errors\n",
        "        raise ve\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error processing {image_path}: {str(e)}\")\n",
        "    skipped_recipes.append(image_path)\n",
        "\n",
        "  time.sleep(4)  # Keep your original delay\n",
        "\n",
        "# Print summary of skipped recipes at the end\n",
        "if skipped_recipes:\n",
        "  print(\"\\nSkipped recipes due to copyright or errors:\")\n",
        "  for path in skipped_recipes:\n",
        "    print(f\"- {path}\")"
      ],
      "metadata": {
        "id": "TX44INEZTCPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_recipes\n"
      ],
      "metadata": {
        "id": "Jq8v37VXTIVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_recipes = []\n",
        "\n",
        "for recipe in extracted_recipes:\n",
        "    if any(keyword in recipe[\"recipe info\"].lower() for keyword in [\"ingredients\", \"instructions\", \"recipe title\"]):\n",
        "        filtered_recipes.append(recipe)\n",
        "    else:\n",
        "        print(f\"Skipping recipe: {recipe['image_path']}\")\n"
      ],
      "metadata": {
        "id": "quko8DenTIHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "DzQmlPNUTSD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file=\"recipe_info.json\"\n",
        "with open(output_file,\"w\") as json_file:\n",
        "  json.dump(filtered_recipes,json_file,indent=4)"
      ],
      "metadata": {
        "id": "MfzQi7XMTTBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EMBEDDINGS"
      ],
      "metadata": {
        "id": "Jg_2_cpRTYTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "7zI5AN4NTS-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"recipe_info.json\",\"r\") as json_file:\n",
        "  recipes=json.load(json_file)"
      ],
      "metadata": {
        "id": "w3E3MmwYTS7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_texts=[recipe[\"recipe info\"] for recipe in recipes]\n",
        "# Option 1: Using sentence-transformers (completely free, runs locally)\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def generate_embeddings_sentence_transformers(recipe_texts):\n",
        "    # Load a pre-trained model (this downloads it once)\n",
        "    model = SentenceTransformer('all-mpnet-base-v2')  # Smaller, faster model\n",
        "    # For higher quality: 'all-mpnet-base-v2'\n",
        "    # all-MiniLM-L6-v2\n",
        "    # Generate embeddings\n",
        "    embeddings = model.encode(recipe_texts)\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# Use like this:\n",
        "embeddings = generate_embeddings_sentence_transformers(recipe_texts)"
      ],
      "metadata": {
        "id": "8ieS5bj7TS5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert emdding to numpy array\n",
        "embedding_matrix=np.array(embeddings)\n",
        "embedding_matrix"
      ],
      "metadata": {
        "id": "3ZL0DRwITS2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "SJcMhw0_ToV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "index=faiss.IndexFlatL2(embedding_matrix.shape[1])\n",
        "index.add(embedding_matrix)\n",
        "# save the index\n",
        "faiss.write_index(index, 'filtered_recipe_index.index')\n",
        "# save metadata\n",
        "metadata=[{'recipe_info':recipe.get('recipe info', 'N/A'),  # Use 'recipe info' key\n",
        "           \"image_path\":recipe['image_path']} for recipe in filtered_recipes]"
      ],
      "metadata": {
        "id": "oLOvBhCYToSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_embeddings(query, index, metadata, k=5, model=None):\n",
        "    # Check if model is provided, otherwise load it\n",
        "    if model is None:\n",
        "        model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "    # Generate the embeddings for the query using sentence-transformers\n",
        "    query_embedding = model.encode([query])[0]\n",
        "    print(f\"The query embedding is {query_embedding}\\n\")\n",
        "\n",
        "    query_vector = np.array(query_embedding).reshape(1, -1)\n",
        "    print(f\"The query vector is {query_vector}\\n\")\n",
        "\n",
        "    # Search faiss index\n",
        "    distances, indices = index.search(query_vector, min(k, len(metadata)))\n",
        "\n",
        "    # Store the indices and distances\n",
        "    stored_indices = indices[0].tolist()\n",
        "    stored_distances = distances[0].tolist()\n",
        "    print(f\"The stored indices are {stored_indices}\\n\")\n",
        "    print(f\"The stored distances are {stored_distances}\\n\")\n",
        "\n",
        "    # Return the results\n",
        "    results = [\n",
        "        (metadata[i]['recipe_info'], dist)\n",
        "        for i, dist in zip(stored_indices, stored_distances)\n",
        "        if 0 <= i < len(metadata)\n",
        "    ]\n",
        "    return results"
      ],
      "metadata": {
        "id": "2ggH3gNQToPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"How to make bread?\"\n",
        "results=query_embeddings(query,index,metadata)\n",
        "results"
      ],
      "metadata": {
        "id": "-tyL0Pn1ToNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_retrieved(results):\n",
        "  combined_content=\"\\n\\n\".join([result[0]for result in results])\n",
        "  return combined_content"
      ],
      "metadata": {
        "id": "iI-2ueO_T9iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_content=combine_retrieved(results)"
      ],
      "metadata": {
        "id": "d4YO30ktT9e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_content"
      ],
      "metadata": {
        "id": "z9M6zCOrT9cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QX_YuvqHT9Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# retrieving with context"
      ],
      "metadata": {
        "id": "LUGisBaqUQJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the system prompt\n",
        "system_prompt4 = f\"\"\"\n",
        "You are highly experienced and expert chef specialized in providing cooking advice.\n",
        "Your main task is to provide information precise and accurate on the combined content.\n",
        "You answer diretly to the query using only information from the provided {combined_content}.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Your goal is to help the user and answer the {query}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VtilM6UvT9XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(query, combined_content, system_prompt):\n",
        "    # Create a model instance with your system instruction\n",
        "    model = genai.GenerativeModel(\n",
        "        model_name='models/gemini-1.5-flash',\n",
        "        system_instruction=system_prompt4  # Remove the '4' suffix\n",
        "    )\n",
        "\n",
        "    # Generate response using Gemini - format as per Gemini API requirements\n",
        "    response = model.generate_content(\n",
        "        contents=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [{\"text\": f\"Query: {query}\\n\\nInformation: {combined_content}\"}]\n",
        "            }\n",
        "        ],\n",
        "        generation_config={\"temperature\": 0}\n",
        "    )\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "IWT5kAsXUHxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the results from the API\n",
        "query = \"How to make bread?\"\n",
        "combined_content = combine_retrieved(results)\n",
        "response = generate_response(query, combined_content, system_prompt3)\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "n-ruESTZUHt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the results from the API\n",
        "query = \"give me  chocolate cake recipe?\"\n",
        "combined_content = combine_retrieved(results)\n",
        "response = generate_response(query, combined_content, system_prompt3)\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "to267reCUHrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RSyrLrJbUHpO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}